# Diamond-Price-Prediction
This classic dataset contains the prices and other attributes of almost 54,000 diamonds. There are 11 attributes included in the dataset including the target price.
This project focuses on predicting diamond prices based on their physical attributes using various machine learning models. Throughout the process, data preprocessing, feature engineering, and outlier removal techniques were applied to improve model accuracy. Multiple modelsâ€”including linear regression, support vector regression, random forest, XGBoost, and a neural networkâ€”were trained and compared. The final results highlight the performance of each model, showing that ensemble and deep learning methods can provide highly accurate price estimations.

ðŸ“Œ Project Overview
This classic dataset contains the prices and other attributes of almost 54,000 diamonds. The dataset includes 11 features, including the target variable: price.
This project aims to predict diamond prices based on their physical characteristics using various machine learning models.

Throughout the process, we applied:

ðŸ”§ Data preprocessing

âœ¨ Feature engineering

ðŸš« Outlier removal

Multiple models were trained and evaluated:

Linear Regression

Support Vector Regression (SVR)

Random Forest

XGBoost

Neural Network (Keras / TensorFlow)

The results show that ensemble and deep learning methods outperform simpler models, providing highly accurate predictions.

ðŸ“‚ Dataset
You can find the original dataset here:
ðŸ”— Kaggle Diamond Dataset

ðŸ§  Technologies Used
Python

Pandas, NumPy

Scikit-learn

XGBoost

TensorFlow / Keras

Matplotlib, Seaborn, Plotly

ðŸ“ˆ Model Comparison
A performance comparison between all models is available inside the notebook.

ðŸ“Œ Conclusion
Among all the models tested, the XGBoost Regressor delivered the best performance in predicting diamond prices. It achieved an impressive RÂ² score of 0.9830, significantly outperforming other models including Linear Regression, SVR, Random Forest, and Neural Network. This result demonstrates the strength of ensemble learning methodsâ€”especially XGBoostâ€”in capturing complex relationships between features and target values in structured datasets.



